{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with our mystery fasta file containing an unknown, interesting sequences we found in our studies, let's use Biopython's http BLAST methods to retrieve a BLAST query result.  We can save the result to an XML file the default output method of the BLAST search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIWWW\n",
    "from Bio import SeqIO\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "# fp = \"./files/dna.example.fasta\"\n",
    "fp = \"./files/dna2.fasta\"\n",
    "records = list(SeqIO.parse(fp, \"fasta\"))\n",
    "\n",
    "# How many records are in a file?\n",
    "print(len(records))\n",
    "\n",
    "f = open(fp).read()\n",
    "print(f.count('>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4894\n",
      "115\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "'annotations',\n",
    " 'dbxrefs',\n",
    " 'description',\n",
    " 'features',\n",
    " 'format',\n",
    " 'id',\n",
    " 'letter_annotations',\n",
    " 'lower',\n",
    " 'name',\n",
    " 'reverse_complement',\n",
    " 'seq',\n",
    " 'translate',\n",
    " 'upper'\n",
    " \"\"\"\n",
    "\n",
    "\n",
    "l_seq = 0\n",
    "s_seq = 0\n",
    "for record in records:\n",
    "    seq_len = len(record.seq)\n",
    "    # print(seq_len)\n",
    "    \n",
    "    # Check if its the longest sequence\n",
    "    if seq_len > l_seq:\n",
    "        l_seq = seq_len\n",
    "        \n",
    "    # Check if its the shortest sequence\n",
    "    if seq_len < s_seq or s_seq == 0:\n",
    "        s_seq = seq_len\n",
    "\n",
    "# What is the longest sequence?\n",
    "print(l_seq)\n",
    "\n",
    "# What is the shortest sequence?\n",
    "print(s_seq)\n",
    "\n",
    "# Is there more than one longest or shortest sequence?\n",
    "\n",
    "# What are their identifiers?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1509\n",
      "1527\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In molecular biology, a reading frame is a way of dividing the DNA sequence of nucleotides into a set of \n",
    "- consecutive, \n",
    "- non-overlapping triplets (or codons). \n",
    "\n",
    "Depending on where we start, there are six possible reading frames: \n",
    "- three in the forward (5' to 3') direction and \n",
    "- three in the reverse (3' to 5'). \n",
    "\n",
    "For instance, the three possible forward reading frames for the sequence AGGTGACACCGCAAGCCTTATATTAGC are:\n",
    "\n",
    "AGG TGA CAC CGC AAG CCT TAT ATT AGC\n",
    "\n",
    "A GGT GAC ACC GCA AGC CTT ATA TTA GC\n",
    "\n",
    "AG GTG ACA CCG CAA GCC TTA TAT TAG C\n",
    "\n",
    "These are called reading frames 1, 2, and 3 respectively. \n",
    "An open reading frame (ORF) is the part of a reading frame that has the potential to encode a protein. \n",
    "It starts with a start codon (ATG), and ends with a stop codon (TAA, TAG or TGA). \n",
    "For instance, ATGAAATAG is an ORF of length 9.\n",
    "\n",
    "Given an input reading frame on the forward strand (1, 2, or 3) your program should be able to \n",
    "identify all ORFs present in each sequence of the FASTA file, and answer the following questions: \n",
    "- What is the length of the longest ORF in the file? \n",
    "- What is the identifier of the sequence containing the longest ORF? \n",
    "- For a given sequence identifier, what is the longest ORF contained in the sequence represented by that identifier? What is the starting position of the longest ORF in the sequence that contains it? The position should indicate the character number in the sequence. For instance, the following ORF in reading frame 1:\n",
    "\n",
    ">sequence1\n",
    "\n",
    "ATGCCCTAG\n",
    "\n",
    "starts at position 1.\n",
    "\n",
    "Note that because the following sequence:\n",
    "\n",
    ">sequence2\n",
    "\n",
    "ATGAAAAAA\n",
    "\n",
    "does not have any stop codon in reading frame 1, we do not consider it to be an ORF in reading frame 1.\"\"\"\n",
    "\n",
    "start_codon = \"ATG\"\n",
    "end_codons = [\"TAA\", \"TAG\", \"TGA\"]\n",
    "longest_orf = 0  # Longest ORF record\n",
    "longest_orf_sp = 0  # Longest ORF record, starting position\n",
    "\n",
    "target_id = \"gi|142022655|gb|EQ086233.1|16\"\n",
    "\n",
    "# Loop through the first three forward frames\n",
    "for n in range(2):\n",
    "    for i, record in enumerate(records):\n",
    "    #     record = record.reverse_complement()\n",
    "    #     print(i)\n",
    "        \n",
    "        # If the target sequence id is not found, just skip to the next record\n",
    "        if record.id != target_id:\n",
    "            continue\n",
    "\n",
    "        # Break the sequence into chunks of 3 letters so that we can analyse the frames\n",
    "        rf_2 = [str(record.seq[i: i + 3]) for i in range(n, len(record), 3)]\n",
    "\n",
    "        start_pos = 0\n",
    "        start_flag = False\n",
    "\n",
    "        # Loop through the sequence chunks\n",
    "        for j, chunk in enumerate(rf_2):\n",
    "            # If a start codon is found, log pos\n",
    "            if chunk == start_codon and not start_flag:\n",
    "                start_pos = j\n",
    "                start_flag = True\n",
    "\n",
    "            # if an end condon is found, log pos\n",
    "            if chunk in end_codons and start_flag:\n",
    "                orf = (j - start_pos + 1) * 3\n",
    "                if orf > longest_orf:\n",
    "                    longest_orf = orf\n",
    "                    longest_orf_sp = start_pos\n",
    "                start_flag = False\n",
    "                \n",
    "print(longest_orf)\n",
    "print(longest_orf_sp * 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "1\n",
      "TGCGCGC found: 36\n",
      "CATCGCC found: 13\n",
      "AATGGCA found: 2\n",
      "CGCGCCG found: 63\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A repeat is a substring of a DNA sequence that occurs in multiple copies (more than one) \n",
    "somewhere in the sequence. \n",
    "\n",
    "Although repeats can occur on both the forward and reverse strands of the DNA sequence, \n",
    "we will only consider repeats on the forward strand here. Also we will allow repeats to overlap themselves. \n",
    "\n",
    "For example, the sequence ACACA contains two copies of the sequence ACA \n",
    "- once at position 1 (index 0 in Python), and \n",
    "- once at position 3. \n",
    "\n",
    "Given a length n, your program should be able to identify all repeats of length n in all sequences\n",
    "in the FASTA file. Your program should also determine how many times each repeat occurs in the file, \n",
    "and which is the most frequent repeat of a given length.\n",
    "\"\"\"\n",
    "\n",
    "n = 7  # Sequence length\n",
    "repeats_tracker = {}  # Dictionary to hold the largest repeats\n",
    "\n",
    "for i, record in enumerate(records):\n",
    "    seq = record.seq\n",
    "#     print(seq)\n",
    "        \n",
    "    # Iterate along the string and find unique repeats\n",
    "    seq_count = {}\n",
    "    for j in range(len(seq) - (n - 1)):\n",
    "        repeat = str(seq[j:j+n])\n",
    "        if repeat not in seq_count:\n",
    "            seq_count[repeat] = 1\n",
    "        else:\n",
    "            seq_count[repeat] += 1\n",
    "            \n",
    "    # Add the repeats to the master dictionary, if largest found\n",
    "    for repeat, val in seq_count.items():\n",
    "        if repeat not in repeats_tracker:\n",
    "            repeats_tracker[repeat] = val\n",
    "        else:\n",
    "            repeats_tracker[repeat] += val\n",
    "\n",
    "max_repeats = max(repeats_tracker.values())\n",
    "print(max_repeats)\n",
    "\n",
    "max_occurrences = list(repeats_tracker.values()).count(max_repeats)\n",
    "print(max_occurrences)\n",
    "\n",
    "print('TGCGCGC found: {}'.format(repeats_tracker.get('TGCGCGC', 0)))\n",
    "print('CATCGCC found: {}'.format(repeats_tracker.get('CATCGCC', 0)))\n",
    "print('AATGGCA found: {}'.format(repeats_tracker.get('AATGGCA', 0)))\n",
    "print('CGCGCCG found: {}'.format(repeats_tracker.get('CGCGCCG', 0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_handle = NCBIWWW.qblast(\"blastn\", \"nt\", fasta_string)\n",
    "\n",
    "with open(\"blast_output.xml\", \"w\") as output_xml:\n",
    "    output_xml.write(result_handle.read())\n",
    "result_handle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the result is saved to file, we do not need to re-run this cell, and thus avoid having to re-run the BLAST query.  With the query result saved to file, we can load the result into a BLAST record object (a type of [python class](https://docs.python.org/3/tutorial/classes.html)) and use Biopython's NCBIXML to return the BLAST record object.  The BLAST record object essentially contains all the information you might need in a BLAST record.  You can view the raw [BLAST record code](http://biopython.org/DIST/docs/api/Bio.Blast.Record-module.html) to see what data are stored in the object.  We can view the alignments, alignment scores, expectation values, and other parameters that are stored in the hsps objects within the BLAST record class.  Because there are typically many alignments for each hit from BLAST, we will just examine the alignments from our top hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_handle = open(\"blast_output.xml\")\n",
    "from Bio.Blast import NCBIXML\n",
    "blast_records = NCBIXML.read(result_handle)\n",
    "for alignment in blast_records.alignments:\n",
    "    for hsp in alignment.hsps:\n",
    "        print(hsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at what the top 10 hits we get from NCBI's Nucleotide (nt) database.  We will view the decriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_handle = open(\"blast_output.xml\")\n",
    "blast_records = NCBIXML.read(result_handle)\n",
    "counter = 0\n",
    "for description in blast_records.descriptions:\n",
    "    print(description)\n",
    "    counter += 1\n",
    "    if counter == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our top hit is a mRNA transcript record from an organism named Drosophila yakuba.  While outside the scope of this tutorial, one could get more information on this record is by using efetch from the nucleotide database of NCBI via Biopython's Entrez module, as shown below.  [EFetch](https://www.ncbi.nlm.nih.gov/books/NBK25499/#chapter4.EFetch) is part of [NCBI's E-Utilities Suite](https://www.ncbi.nlm.nih.gov/books/NBK25497/), which provides programmatic access to records and information from NCBI's Entrez databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "Entrez.email = \"anon@example.com\"     # Always tell NCBI who you are\n",
    "top_hit_record = Entrez.efetch(db=\"nucleotide\", id=\"969472224\", rettype=\"gb\", retmode=\"text\")\n",
    "print(top_hit_record.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returning to our BLAST query, let's explore a little further different parameters for BLAST.  We can first print out the parameters for the qblast function using inspect.signature(function_name).  One could also print the more verbose help(function_name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.signature(NCBIWWW.qblast))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many parameters for this function.  Many of them need not be adjusted in most cases.  For simplicity, let's focus on the four parameters below.  First, we create a python dictionary for a few different parameters we would like to adjust to ultimately compare outputs.  We can start by adjusting the database we want to query against.  We will store the output of each blast XML separately should we choose to access the data at a later point.  As we loop through each blast query for the different programs, we will collect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "blast_params = {'program': 'blastn', 'database': 'nt', 'sequence': fasta_string, 'expect': 10.0}\n",
    "blast_params['database'] = ['nt', 'refseq_representative_genomes']\n",
    "print_data = pd.DataFrame()\n",
    "for database in blast_params['database']:\n",
    "    db_values = {}\n",
    "    #result = NCBIWWW.qblast(blast_params['program'], database, blast_params['sequence'], expect=blast_params['expect'])\n",
    "    file_name = \"blast_output_\" + database + \".xml\"\n",
    "    #with open(file_name, \"w\") as output_xml:\n",
    "    #    output_xml.write(result.read())\n",
    "    result.close()\n",
    "    result_input = open(file_name)\n",
    "    blast_records = NCBIXML.read(result_input)\n",
    "    for description in blast_records.descriptions:\n",
    "        if 'score' in db_values:\n",
    "            db_values['score'].append(description.score)\n",
    "        else:\n",
    "            db_values['score'] = [description.score]\n",
    "        if 'e-value' in db_values:\n",
    "            db_values['e-value'].append(description.e)\n",
    "        else:\n",
    "            db_values['e-value'] = [description.e]\n",
    "    df = pd.DataFrame.from_dict(db_values)\n",
    "    df['database'] = database[0:6] # we simply limit the name to the first 6 characters for easier viewing\n",
    "    frames = [print_data, df]\n",
    "    print_data = pd.concat(frames, ignore_index=True)\n",
    "print_data.boxplot('score', by='database')\n",
    "print_data.boxplot('e-value', by='database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "blast_params = {'program': 'blastn', 'database': 'nt', 'sequence': fasta_string, 'expect': 10.0}\n",
    "blast_params['database'] = ['nt', 'refseq_representative_genomes']\n",
    "print_data = pd.DataFrame()\n",
    "for database in blast_params['database']:\n",
    "    db_values = {}\n",
    "    #result = NCBIWWW.qblast(blast_params['program'], database, blast_params['sequence'], expect=blast_params['expect'])\n",
    "    file_name = \"blast_output_\" + database + \".xml\"\n",
    "    #with open(file_name, \"w\") as output_xml:\n",
    "    #    output_xml.write(result.read())\n",
    "    #result.close()\n",
    "    result_input = open(file_name)\n",
    "    blast_records = NCBIXML.read(result_input)\n",
    "    for description in blast_records.descriptions:\n",
    "        if 'score' in db_values:\n",
    "            db_values['score'].append(description.score)\n",
    "        else:\n",
    "            db_values['score'] = [description.score]\n",
    "        if 'e-value' in db_values:\n",
    "            db_values['e-value'].append(description.e)\n",
    "        else:\n",
    "            db_values['e-value'] = [description.e]\n",
    "    df = pd.DataFrame.from_dict(db_values)\n",
    "    df['database'] = database[0:6] # we simply limit the name to the first 6 characters for easier viewing\n",
    "    frames = [print_data, df]\n",
    "    print_data = pd.concat(frames, ignore_index=True)\n",
    "print_data.boxplot('score', by='database')\n",
    "print_data.boxplot('e-value', by='database')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based our initial results, our top hit for a genome in NCBI Entrez has an accession number of AE014135.4.  We can use this entry to explore genes that are present on this model organism to see what potential biological activities our DNA sequence might be involved with.  Before we move on to notebook 2, we need to find out where on this model genomic sequence our test sequence lies (we would not want to look at ALL of the genes on this chromosome, as our sequence only applies to a small portion of that chromosome)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SearchIO\n",
    "qresults = next(SearchIO.parse('blast_output.xml', 'blast-xml'))\n",
    "print(qresults[3]) # the 4th target is out first genomic hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genomics)",
   "language": "python",
   "name": "genomics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
